{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harsh Pande\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D, Convolution2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "#from tensorflow.keras.optimizers import SGD,RMSprop,adam,Adam,Adagrad\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import theano\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import cv2\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "from tqdm import tqdm\n",
    "import glob as glob\n",
    "import imutils\n",
    "\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = \"C:/Users/Harsh Pande/Desktop/Final Mirror Dataset/\"\n",
    "#p2 = \"C:/Users/prana/Desktop/DataScience/processed\"\n",
    "img_rows = 40\n",
    "img_cols = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imglist = os.listdir(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26097\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(imglist)\n",
    "print(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'files = glob.glob (\"C:/Users/prana/Desktop/DataScience/Final Mirror Dataset/*.jpg\")\\ni = 0\\nfor myFile in files:\\n    image = cv2.imread (myFile)\\n    mirror_img = np.fliplr(image)\\n    #rotated = imutils.rotate(image, 270)\\n    path = \\'C:/Users/prana/Desktop/DataScience/flipped\\'\\n    cv2.imwrite(os.path.join(path , \"img\"+str(i)+\".jpg\"), mirror_img)\\n    i = i + 1\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''files = glob.glob (\"C:/Users/prana/Desktop/DataScience/Final Mirror Dataset/*.jpg\")\n",
    "i = 0\n",
    "for myFile in files:\n",
    "    image = cv2.imread (myFile)\n",
    "    mirror_img = np.fliplr(image)\n",
    "    #rotated = imutils.rotate(image, 270)\n",
    "    path = 'C:/Users/prana/Desktop/DataScience/flipped'\n",
    "    cv2.imwrite(os.path.join(path , \"img\"+str(i)+\".jpg\"), mirror_img)\n",
    "    i = i + 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26097, 40, 40, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "X_data = []\n",
    "files = glob.glob (\"C:/Users/Harsh Pande/Desktop/Final Mirror Dataset/*.jpg\")\n",
    "for myFile in files:\n",
    "    #print(myFile)\n",
    "    image = cv2.imread (myFile)\n",
    "    resized_image = cv2.resize(image, (img_rows,img_cols)) \n",
    "    X_data.append (resized_image)\n",
    "\n",
    "final = np.array(X_data)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26097, 1600, 3)\n",
      "(4800, 26097)\n",
      "(26097, 4800)\n"
     ]
    }
   ],
   "source": [
    "pixel_lists = final.reshape(final.shape[:-3] + (-1, 3))\n",
    "print(pixel_lists.shape)  \n",
    "\n",
    "new1 = pixel_lists.reshape((pixel_lists.shape[1]*pixel_lists.shape[2]),pixel_lists.shape[0])\n",
    "print(new1.shape)\n",
    "new2 = new1.transpose()\n",
    "print(new2.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "label = np.ones((n_samples,),dtype = int)\n",
    "label[0:8699] = 0\n",
    "label[8700:17399] = 1\n",
    "label[17400:26099] = 2\n",
    "print(label[5799])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, Label =shuffle(new2,label,random_state=2)\n",
    "train_data = [data, Label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26097, 4800)\n",
      "(26097,)\n",
      "[116 255  48 255 156 255 153 186  56 116 252  83 119 127 104  35 159 156\n",
      "  55 130  69 139 255 133 255 126 255  70 250 114 152 138  95 254 146 242\n",
      " 110  48 183  49  43 156 101 173  96 255  82 255  31 255 189  82 222 109\n",
      " 170 126 252 139 255 140 254 108 251 175  27 195  33 101 109 135 109  32\n",
      " 255 146 177  92 157  68 107 253 153 255 145 255  96 254 114  70  73 102\n",
      "  13  46  59 131 115 186  38 251  33 175  66 124 255  75 255 215 255 126\n",
      " 125  60  42  88 171 255  58  68  29  48 132  52  43 170 162 254  74 255\n",
      "  60 255  54 255  70 192 183  76 149 119 255 159 255  84 235 111 164  97\n",
      "  47 184  24 107  15  32 104  68 255  68  50 142  20  95  98 255 165 255\n",
      " 132 255  96 222  96  58 194  21  98 101  87  13  69  68 117  59  57 100\n",
      "  23 170 255 115 255  85 255 170 205  41  39  39 122 116 137  81 121  60\n",
      "  28 127  95  89  85 255  55 255 169 255  98 255 116 125  52  62  55  43\n",
      " 255  75 250 156 155 164 144  93  37 136 146 147 141  77 255 152 255  40\n",
      "  86  87  56  19 167 255 178 255 107 255  92 176 191 112 102 138  66  50\n",
      " 163  91 110 255 110  71 137 114 211 154 255 202 255 125 255 166 163  20\n",
      "  97 249 122  73  75 130  89 102  11  82  53 117  88 254  95 255 215 255\n",
      " 142 250 159 114 179  44 247 128 252 130  32  23]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0].shape)\n",
    "print(train_data[1].shape)\n",
    "print(train_data[0][2][-300:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "batch_size = 2048\n",
    "n_epochs = 20\n",
    "n_classes = 3\n",
    "img_channel = 3\n",
    "n_filters = 64\n",
    "n_filters2 = 32\n",
    "n_filters3 = 32\n",
    "n_pool = 2\n",
    "n_conv = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "(x , y) = (train_data[0],train_data[1])\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.45,random_state=33)\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],3,img_rows,img_cols)\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0],3,img_rows,img_cols)\n",
    "\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "x_train /= 255#standardization\n",
    "x_test /= 255\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train,n_classes)\n",
    "y_test = np_utils.to_categorical(y_test,n_classes)\n",
    "\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changes1 ===> n_filters, activation,dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harsh Pande\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(3, 40, 40..., padding=\"valid\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\Harsh Pande\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "  \n",
      "C:\\Users\\Harsh Pande\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Harsh Pande\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "  \n",
      "C:\\Users\\Harsh Pande\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "C:\\Users\\Harsh Pande\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 38, 38)        1792      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 38, 38)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 19, 19)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 17, 17)        18464     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 17, 17)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 8, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 6, 6)          9248      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 3, 3)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               147968    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1539      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 179,011\n",
      "Trainable params: 179,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model  = Sequential()\n",
    "from time import time\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "model.add(Convolution2D(n_filters,n_conv,n_conv,border_mode='valid',input_shape=(3,img_rows,img_cols)))#n_filters should be in power of 2\n",
    "convout1 = Activation('relu')\n",
    "model.add(convout1)\n",
    "model.add(MaxPooling2D(pool_size=(n_pool,n_pool),dim_ordering=\"th\"))\n",
    "#model.add(Dropout(0.2))#0.119\n",
    "\n",
    "model.add(Convolution2D(n_filters2,n_conv,n_conv))\n",
    "convout2 = Activation('relu')#(0,x) if x is neg it will be 0 else whatever is the value of x\n",
    "model.add(convout2)\n",
    "model.add(MaxPooling2D(pool_size=(n_pool,n_pool),dim_ordering=\"th\"))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Convolution2D(n_filters3,n_conv,n_conv))\n",
    "convout2 = Activation('relu')\n",
    "model.add(convout2)\n",
    "model.add(MaxPooling2D(pool_size=(n_pool,n_pool),dim_ordering=\"th\"))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(512))   ###Changes- latest\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(n_classes))  ###Changes\n",
    "model.add(Dropout(0.25))##changed position\n",
    "\n",
    "model.add(Activation('softmax'))#e to power of x/summation of e to the power of x(basically gives us the probability)\n",
    "\n",
    "\n",
    "optimizer = Adam()\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizer ,metrics=['accuracy'])\n",
    "#tensorboard = TensorBoard(log_dir=\"./Graph\".format(time()))\n",
    "tensorboard = TensorBoard(log_dir=\"./Graph\", histogram_freq=0, write_graph=True, write_images=True)\n",
    "#keras.optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14353 samples, validate on 11744 samples\n",
      "Epoch 1/20\n",
      "14353/14353 [==============================] - ETA: 2:31 - loss: 1.1080 - acc: 0.332 - ETA: 1:58 - loss: 1.1176 - acc: 0.337 - ETA: 1:31 - loss: 1.1108 - acc: 0.340 - ETA: 1:07 - loss: 1.1070 - acc: 0.342 - ETA: 44s - loss: 1.1057 - acc: 0.340 - ETA: 22s - loss: 1.1039 - acc: 0.34 - ETA: 0s - loss: 1.1027 - acc: 0.3475 - 210s 15ms/step - loss: 1.1027 - acc: 0.3477 - val_loss: 1.1069 - val_acc: 0.3271\n",
      "Epoch 2/20\n",
      "14353/14353 [==============================] - ETA: 1:57 - loss: 1.1053 - acc: 0.337 - ETA: 1:34 - loss: 1.1044 - acc: 0.332 - ETA: 1:18 - loss: 1.1019 - acc: 0.338 - ETA: 58s - loss: 1.0998 - acc: 0.342 - ETA: 38s - loss: 1.0990 - acc: 0.34 - ETA: 19s - loss: 1.0979 - acc: 0.34 - ETA: 0s - loss: 1.0973 - acc: 0.3541 - 205s 14ms/step - loss: 1.0973 - acc: 0.3541 - val_loss: 1.0919 - val_acc: 0.3298\n",
      "Epoch 3/20\n",
      "14353/14353 [==============================] - ETA: 2:28 - loss: 1.0905 - acc: 0.339 - ETA: 1:55 - loss: 1.0896 - acc: 0.343 - ETA: 1:26 - loss: 1.0887 - acc: 0.386 - ETA: 1:06 - loss: 1.0886 - acc: 0.386 - ETA: 44s - loss: 1.0886 - acc: 0.385 - ETA: 22s - loss: 1.0883 - acc: 0.38 - ETA: 0s - loss: 1.0874 - acc: 0.3795 - 211s 15ms/step - loss: 1.0875 - acc: 0.3794 - val_loss: 1.0834 - val_acc: 0.3311\n",
      "Epoch 4/20\n",
      "14353/14353 [==============================] - ETA: 2:15 - loss: 1.0802 - acc: 0.398 - ETA: 2:08 - loss: 1.0841 - acc: 0.369 - ETA: 1:43 - loss: 1.0895 - acc: 0.353 - ETA: 1:14 - loss: 1.0909 - acc: 0.346 - ETA: 48s - loss: 1.0893 - acc: 0.343 - ETA: 23s - loss: 1.0870 - acc: 0.34 - ETA: 0s - loss: 1.0849 - acc: 0.3841 - 225s 16ms/step - loss: 1.0849 - acc: 0.3840 - val_loss: 1.0732 - val_acc: 0.5052\n",
      "Epoch 5/20\n",
      "14353/14353 [==============================] - ETA: 1:55 - loss: 1.0748 - acc: 0.473 - ETA: 1:34 - loss: 1.0749 - acc: 0.471 - ETA: 1:16 - loss: 1.0732 - acc: 0.475 - ETA: 57s - loss: 1.0708 - acc: 0.503 - ETA: 40s - loss: 1.0686 - acc: 0.52 - ETA: 20s - loss: 1.0663 - acc: 0.53 - ETA: 0s - loss: 1.0639 - acc: 0.5412 - 211s 15ms/step - loss: 1.0639 - acc: 0.5414 - val_loss: 1.0490 - val_acc: 0.3524\n",
      "Epoch 6/20\n",
      "14353/14353 [==============================] - ETA: 2:03 - loss: 1.0444 - acc: 0.400 - ETA: 1:44 - loss: 1.0534 - acc: 0.383 - ETA: 1:22 - loss: 1.0523 - acc: 0.386 - ETA: 1:00 - loss: 1.0494 - acc: 0.391 - ETA: 40s - loss: 1.0438 - acc: 0.430 - ETA: 20s - loss: 1.0393 - acc: 0.46 - ETA: 0s - loss: 1.0359 - acc: 0.4738 - 199s 14ms/step - loss: 1.0359 - acc: 0.4739 - val_loss: 0.9981 - val_acc: 0.5393\n",
      "Epoch 7/20\n",
      "14353/14353 [==============================] - ETA: 1:55 - loss: 1.0046 - acc: 0.516 - ETA: 1:36 - loss: 0.9954 - acc: 0.548 - ETA: 1:18 - loss: 0.9885 - acc: 0.558 - ETA: 58s - loss: 0.9829 - acc: 0.574 - ETA: 39s - loss: 0.9784 - acc: 0.58 - ETA: 20s - loss: 0.9715 - acc: 0.60 - ETA: 0s - loss: 0.9660 - acc: 0.6059 - 201s 14ms/step - loss: 0.9659 - acc: 0.6059 - val_loss: 0.8881 - val_acc: 0.7447\n",
      "Epoch 8/20\n",
      "14353/14353 [==============================] - ETA: 2:02 - loss: 0.8977 - acc: 0.674 - ETA: 1:38 - loss: 0.8950 - acc: 0.652 - ETA: 1:18 - loss: 0.8857 - acc: 0.654 - ETA: 58s - loss: 0.8774 - acc: 0.659 - ETA: 38s - loss: 0.8673 - acc: 0.67 - ETA: 19s - loss: 0.8573 - acc: 0.68 - ETA: 0s - loss: 0.8474 - acc: 0.6934 - 197s 14ms/step - loss: 0.8473 - acc: 0.6935 - val_loss: 0.8136 - val_acc: 0.5920\n",
      "Epoch 9/20\n",
      "14353/14353 [==============================] - ETA: 2:14 - loss: 0.8267 - acc: 0.585 - ETA: 1:50 - loss: 0.7850 - acc: 0.658 - ETA: 1:28 - loss: 0.7884 - acc: 0.649 - ETA: 1:06 - loss: 0.7688 - acc: 0.674 - ETA: 44s - loss: 0.7540 - acc: 0.688 - ETA: 21s - loss: 0.7475 - acc: 0.69 - ETA: 0s - loss: 0.7345 - acc: 0.7061 - 212s 15ms/step - loss: 0.7343 - acc: 0.7063 - val_loss: 0.6093 - val_acc: 0.8078\n",
      "Epoch 10/20\n",
      "14353/14353 [==============================] - ETA: 2:33 - loss: 0.6574 - acc: 0.749 - ETA: 2:02 - loss: 0.6278 - acc: 0.778 - ETA: 1:34 - loss: 0.6211 - acc: 0.778 - ETA: 1:08 - loss: 0.6134 - acc: 0.777 - ETA: 44s - loss: 0.6004 - acc: 0.785 - ETA: 22s - loss: 0.5917 - acc: 0.78 - ETA: 0s - loss: 0.5812 - acc: 0.7959 - 225s 16ms/step - loss: 0.5813 - acc: 0.7958 - val_loss: 0.7403 - val_acc: 0.6879\n",
      "Epoch 11/20\n",
      "14353/14353 [==============================] - ETA: 2:20 - loss: 0.8069 - acc: 0.609 - ETA: 1:54 - loss: 0.7188 - acc: 0.648 - ETA: 1:33 - loss: 0.6594 - acc: 0.693 - ETA: 1:09 - loss: 0.6337 - acc: 0.714 - ETA: 46s - loss: 0.6187 - acc: 0.722 - ETA: 23s - loss: 0.6077 - acc: 0.72 - ETA: 0s - loss: 0.5929 - acc: 0.7379 - 236s 16ms/step - loss: 0.5926 - acc: 0.7380 - val_loss: 0.4092 - val_acc: 0.9162\n",
      "Epoch 12/20\n",
      "14353/14353 [==============================] - ETA: 2:14 - loss: 0.4696 - acc: 0.851 - ETA: 1:48 - loss: 0.4635 - acc: 0.847 - ETA: 1:26 - loss: 0.4550 - acc: 0.849 - ETA: 1:06 - loss: 0.4478 - acc: 0.853 - ETA: 45s - loss: 0.4429 - acc: 0.857 - ETA: 22s - loss: 0.4412 - acc: 0.85 - ETA: 0s - loss: 0.4346 - acc: 0.8609 - 222s 15ms/step - loss: 0.4345 - acc: 0.8609 - val_loss: 0.3213 - val_acc: 0.9200\n",
      "Epoch 13/20\n",
      "14353/14353 [==============================] - ETA: 2:07 - loss: 0.3894 - acc: 0.854 - ETA: 1:46 - loss: 0.3840 - acc: 0.856 - ETA: 1:25 - loss: 0.3752 - acc: 0.863 - ETA: 1:04 - loss: 0.3722 - acc: 0.863 - ETA: 42s - loss: 0.3676 - acc: 0.866 - ETA: 21s - loss: 0.3620 - acc: 0.86 - ETA: 0s - loss: 0.3585 - acc: 0.8687 - 226s 16ms/step - loss: 0.3585 - acc: 0.8686 - val_loss: 0.3139 - val_acc: 0.9021\n",
      "Epoch 14/20\n",
      "14353/14353 [==============================] - ETA: 2:35 - loss: 0.4250 - acc: 0.815 - ETA: 2:10 - loss: 0.4098 - acc: 0.819 - ETA: 1:45 - loss: 0.3744 - acc: 0.843 - ETA: 1:19 - loss: 0.3604 - acc: 0.851 - ETA: 52s - loss: 0.3585 - acc: 0.853 - ETA: 26s - loss: 0.3511 - acc: 0.85 - ETA: 0s - loss: 0.3398 - acc: 0.8633 - 263s 18ms/step - loss: 0.3396 - acc: 0.8634 - val_loss: 0.2121 - val_acc: 0.9493\n",
      "Epoch 15/20\n",
      "14353/14353 [==============================] - ETA: 2:44 - loss: 0.3064 - acc: 0.883 - ETA: 2:13 - loss: 0.2885 - acc: 0.895 - ETA: 1:44 - loss: 0.2781 - acc: 0.900 - ETA: 1:17 - loss: 0.2760 - acc: 0.898 - ETA: 51s - loss: 0.2756 - acc: 0.897 - ETA: 25s - loss: 0.2699 - acc: 0.90 - ETA: 0s - loss: 0.2660 - acc: 0.9009 - 255s 18ms/step - loss: 0.2659 - acc: 0.9010 - val_loss: 0.1414 - val_acc: 0.9728\n",
      "Epoch 16/20\n",
      "14353/14353 [==============================] - ETA: 2:37 - loss: 0.2313 - acc: 0.911 - ETA: 2:08 - loss: 0.2307 - acc: 0.915 - ETA: 1:41 - loss: 0.2280 - acc: 0.916 - ETA: 1:16 - loss: 0.2282 - acc: 0.915 - ETA: 50s - loss: 0.2263 - acc: 0.914 - ETA: 25s - loss: 0.2225 - acc: 0.91 - ETA: 0s - loss: 0.2208 - acc: 0.9159 - 251s 18ms/step - loss: 0.2208 - acc: 0.9159 - val_loss: 0.1206 - val_acc: 0.9746\n",
      "Epoch 17/20\n",
      "14353/14353 [==============================] - ETA: 2:33 - loss: 0.2094 - acc: 0.912 - ETA: 2:04 - loss: 0.2116 - acc: 0.911 - ETA: 1:40 - loss: 0.2059 - acc: 0.914 - ETA: 1:15 - loss: 0.2021 - acc: 0.915 - ETA: 51s - loss: 0.2012 - acc: 0.915 - ETA: 25s - loss: 0.2010 - acc: 0.91 - ETA: 0s - loss: 0.1990 - acc: 0.9150 - 252s 18ms/step - loss: 0.1991 - acc: 0.9151 - val_loss: 0.0939 - val_acc: 0.9803\n",
      "Epoch 18/20\n",
      "14353/14353 [==============================] - ETA: 2:28 - loss: 0.1846 - acc: 0.916 - ETA: 2:03 - loss: 0.1839 - acc: 0.917 - ETA: 1:40 - loss: 0.1810 - acc: 0.919 - ETA: 1:15 - loss: 0.1763 - acc: 0.922 - ETA: 50s - loss: 0.1729 - acc: 0.925 - ETA: 25s - loss: 0.1742 - acc: 0.92 - ETA: 0s - loss: 0.1730 - acc: 0.9242 - 249s 17ms/step - loss: 0.1729 - acc: 0.9243 - val_loss: 0.0726 - val_acc: 0.9844\n",
      "Epoch 19/20\n",
      "14353/14353 [==============================] - ETA: 2:45 - loss: 0.1503 - acc: 0.932 - ETA: 2:13 - loss: 0.1538 - acc: 0.933 - ETA: 1:44 - loss: 0.1597 - acc: 0.931 - ETA: 1:18 - loss: 0.1597 - acc: 0.929 - ETA: 51s - loss: 0.1567 - acc: 0.930 - ETA: 25s - loss: 0.1596 - acc: 0.92 - ETA: 0s - loss: 0.1574 - acc: 0.9293 - 252s 18ms/step - loss: 0.1574 - acc: 0.9294 - val_loss: 0.0606 - val_acc: 0.9868\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14353/14353 [==============================] - ETA: 2:29 - loss: 0.1469 - acc: 0.933 - ETA: 2:04 - loss: 0.1453 - acc: 0.938 - ETA: 1:39 - loss: 0.1446 - acc: 0.935 - ETA: 1:14 - loss: 0.1483 - acc: 0.933 - ETA: 49s - loss: 0.1474 - acc: 0.933 - ETA: 24s - loss: 0.1458 - acc: 0.93 - ETA: 0s - loss: 0.1462 - acc: 0.9322 - 246s 17ms/step - loss: 0.1461 - acc: 0.9323 - val_loss: 0.0517 - val_acc: 0.9881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea3c4ea588>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#history = model.fit(x_train,y_train,batch_size=batch_size,epochs=n_epochs,verbose=1,validation_data=(x_test,y_test), callbacks=[tensorboard])\n",
    "model.fit(x_train,y_train,batch_size=batch_size,epochs=n_epochs,verbose=1,validation_data=(x_test,y_test), callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Middle\n",
      "[[0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('C:/Users/Harsh Pande/Desktop/Data Science/12.jpg', target_size = (40, 40))\n",
    "#test_image = test_image.convert(\"L\"\n",
    "test_image = image.img_to_array(test_image)\n",
    "#print(test_image.shape)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "\n",
    "\n",
    "\n",
    "if (result[0][0] > result[0][1]) and (result[0][0] > result[0][2]):\n",
    "    print(\"Infant\")\n",
    "if (result[0][1] > result[0][0]) and (result[0][1] > result[0][2]):\n",
    "    print(\"Middle\")\n",
    "elif (result[0][2] > result[0][0]) and (result[0][2] > result[0][1]):\n",
    "    print(\"Old\")\n",
    "        \n",
    "\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Middle\n",
      "[[0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "'''import cv2\n",
    "\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "for i in range(1):\n",
    "    return_value, image = camera.read()\n",
    "    cv2.imwrite('opencv'+str(i)+'.png', image)\n",
    "\n",
    "\n",
    "from PIL import Image \n",
    "im = Image.open(\"C:/Users/prana/opencv0.png\") \n",
    "\n",
    "im.save(\"C:/Users/prana/img.jpg\")\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "t = 3\n",
    "time.sleep(t)'''\n",
    "\n",
    "\n",
    "\n",
    "'''import numpy as np\n",
    "#from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "#test_image = image.load_img(\"C:/Users/prana/img.jpg\", target_size = (40, 40))\n",
    "\n",
    "\n",
    "test_image = image.load_img(\"C:/Users/Harsh Pande/Desktop/Data Science/2.jpg\", target_size = (40, 40))\n",
    "\n",
    "\n",
    "#test_image = test_image.convert(\"L\")\n",
    "test_image = image.img_to_array(test_image)\n",
    "#print(test_image.shape)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "\n",
    "\n",
    "\n",
    "if (result[0][0] > result[0][1]) and (result[0][0] > result[0][2]):\n",
    "    print(\"Infant\")\n",
    "if (result[0][1] > result[0][0]) and (result[0][1] > result[0][2]):\n",
    "    print(\"Middle\")\n",
    "elif (result[0][2] > result[0][0]) and (result[0][2] > result[0][1]):\n",
    "    print(\"Old\")\n",
    "        \n",
    "\n",
    "\n",
    "print(result)\n",
    "\n",
    "\n",
    "#del(camera)'''\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "test_image = image.load_img('C:/Users/Harsh Pande/Desktop/Data Science/kid.40.jpg', target_size = (40, 40))\n",
    "#test_image = test_image.convert(\"L\"\n",
    "test_image = image.img_to_array(test_image)\n",
    "#print(test_image.shape)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "\n",
    "\n",
    "\n",
    "if (result[0][0] > result[0][1]) and (result[0][0] > result[0][2]):\n",
    "    print(\"Infant\")\n",
    "if (result[0][1] > result[0][0]) and (result[0][1] > result[0][2]):\n",
    "    print(\"Middle\")\n",
    "elif (result[0][2] > result[0][0]) and (result[0][2] > result[0][1]):\n",
    "    print(\"Old\")\n",
    "        \n",
    "\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all data in history\n",
    "\"\"\"print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\"\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
